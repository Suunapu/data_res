{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions\n",
    "Hello. In this notebook I will be exploring and utilizing data science techinques on both numerical and text based data.\n",
    "\n",
    "The dataset that I will be using is taken from the Kaggle competition https://www.kaggle.com/c/job-salary-prediction\n",
    "\n",
    "I will use a combination of Naive Bayes and a Random Forest to make an ensemble of voters. I'm not promising accurate and good predictions in this notebook, but I am promising exploration of different methods and uses of ensembles and the relative effectiveness of those methods.\n",
    "\n",
    "## First look at Data\n",
    "\n",
    "Let's load in the data and see what we're working with here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "salary_table = pd.read_csv('C:/Users/Snapu/Downloads/CIS datasets/Train_rev1/Train_rev1.csv')\n",
    "salary_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "Title                      1\n",
       "FullDescription            0\n",
       "LocationRaw                0\n",
       "LocationNormalized         0\n",
       "ContractType          179326\n",
       "ContractTime           63905\n",
       "Company                32430\n",
       "Category                   0\n",
       "SalaryRaw                  0\n",
       "SalaryNormalized           0\n",
       "SourceName                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(salary_table))\n",
    "salary_table.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContractType null percentage: 0.732636619166\n",
      "ContractTime null percentage: 0.261083965224\n",
      "Company null percentage: 0.132492809518\n"
     ]
    }
   ],
   "source": [
    "print(\"ContractType null percentage: \" +str(179326.0/244768))\n",
    "print(\"ContractTime null percentage: \" +str(63905.0/244768))\n",
    "print(\"Company null percentage: \" + str(32430.0/244768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.447680e+05</td>\n",
       "      <td>244767</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768</td>\n",
       "      <td>65442</td>\n",
       "      <td>180863</td>\n",
       "      <td>212338</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768.000000</td>\n",
       "      <td>244767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>135435</td>\n",
       "      <td>242138</td>\n",
       "      <td>20986</td>\n",
       "      <td>2732</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20812</td>\n",
       "      <td>29</td>\n",
       "      <td>97286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>What is expected of you as a Registered Nurse ...</td>\n",
       "      <td>London</td>\n",
       "      <td>UK</td>\n",
       "      <td>full_time</td>\n",
       "      <td>permanent</td>\n",
       "      <td>UKStaffsearch</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>50,000-74,999 yearly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>totaljobs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>18</td>\n",
       "      <td>15605</td>\n",
       "      <td>41093</td>\n",
       "      <td>57538</td>\n",
       "      <td>151521</td>\n",
       "      <td>4997</td>\n",
       "      <td>38483</td>\n",
       "      <td>1923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.970142e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34122.577576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.129813e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17640.543124</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.261263e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.869550e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21500.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.993700e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.162606e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42500.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.270524e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id                         Title  \\\n",
       "count   2.447680e+05                        244767   \n",
       "unique           NaN                        135435   \n",
       "top              NaN  Business Development Manager   \n",
       "freq             NaN                           921   \n",
       "mean    6.970142e+07                           NaN   \n",
       "std     3.129813e+06                           NaN   \n",
       "min     1.261263e+07                           NaN   \n",
       "25%     6.869550e+07                           NaN   \n",
       "50%     6.993700e+07                           NaN   \n",
       "75%     7.162606e+07                           NaN   \n",
       "max     7.270524e+07                           NaN   \n",
       "\n",
       "                                          FullDescription LocationRaw  \\\n",
       "count                                              244768      244768   \n",
       "unique                                             242138       20986   \n",
       "top     What is expected of you as a Registered Nurse ...      London   \n",
       "freq                                                   18       15605   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "       LocationNormalized ContractType ContractTime        Company Category  \\\n",
       "count              244768        65442       180863         212338   244768   \n",
       "unique               2732            2            2          20812       29   \n",
       "top                    UK    full_time    permanent  UKStaffsearch  IT Jobs   \n",
       "freq                41093        57538       151521           4997    38483   \n",
       "mean                  NaN          NaN          NaN            NaN      NaN   \n",
       "std                   NaN          NaN          NaN            NaN      NaN   \n",
       "min                   NaN          NaN          NaN            NaN      NaN   \n",
       "25%                   NaN          NaN          NaN            NaN      NaN   \n",
       "50%                   NaN          NaN          NaN            NaN      NaN   \n",
       "75%                   NaN          NaN          NaN            NaN      NaN   \n",
       "max                   NaN          NaN          NaN            NaN      NaN   \n",
       "\n",
       "                   SalaryRaw  SalaryNormalized     SourceName  \n",
       "count                 244768     244768.000000         244767  \n",
       "unique                 97286               NaN            167  \n",
       "top     50,000-74,999 yearly               NaN  totaljobs.com  \n",
       "freq                    1923               NaN          48149  \n",
       "mean                     NaN      34122.577576            NaN  \n",
       "std                      NaN      17640.543124            NaN  \n",
       "min                      NaN       5000.000000            NaN  \n",
       "25%                      NaN      21500.000000            NaN  \n",
       "50%                      NaN      30000.000000            NaN  \n",
       "75%                      NaN      42500.000000            NaN  \n",
       "max                      NaN     200000.000000            NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_table.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the ContractType isn't very helpful with only 2 unique values and 73.26% missing values. I think it's safe to say we can drop that column and not worry about it. The missing company values are tricky to recover, Im not sure right now how I would go about that. The contract time isn't very important I think so I won't worry too much about the generation of that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Engineering Systems Analyst   \n",
       "1                            Stress Engineer Glasgow   \n",
       "2                   Modelling and simulation analyst   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractTime  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking    permanent   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow    permanent   \n",
       "2  Hampshire, South East, South East          Hampshire    permanent   \n",
       "3     Surrey, South East, South East             Surrey    permanent   \n",
       "4     Surrey, South East, South East             Surrey    permanent   \n",
       "\n",
       "                        Company          Category  \\\n",
       "0  Gregory Martin International  Engineering Jobs   \n",
       "1  Gregory Martin International  Engineering Jobs   \n",
       "2  Gregory Martin International  Engineering Jobs   \n",
       "3  Gregory Martin International  Engineering Jobs   \n",
       "4  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized  \n",
       "0              20000 - 30000/annum 20-30K             25000  \n",
       "1              25000 - 35000/annum 25-35K             30000  \n",
       "2              20000 - 40000/annum 20-40K             30000  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  \n",
       "4              20000 - 30000/annum 20-30K             25000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_table = salary_table.drop(['Id'], axis=1)\n",
    "salary_table = salary_table.drop(['ContractType'], axis=1)\n",
    "salary_table = salary_table.drop(['SourceName'], axis=1)\n",
    "salary_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to use the normalized columns to make more general predictions as I think the loss of detail will make a stronger prediction. Lets take a look at the amount of unique values in the SalaryNormalized column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of Salaries: [5000] [200000]\n",
      "Sample Mean of Salaries: 34122.5775755\n",
      "Sample Standard Deviation of Salaries: 17640.5431239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8454"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_salaries = salary_table.SalaryNormalized.unique()\n",
    "print(\"Range of Salaries: \"+str(sorted(unique_salaries)[:1]) + \" \"+str(sorted(unique_salaries)[-1:]))\n",
    "print(\"Sample Mean of Salaries: \" + str(salary_table.SalaryNormalized.mean()))\n",
    "print(\"Sample Standard Deviation of Salaries: \" + str((salary_table.SalaryNormalized.var())**.5))\n",
    "len(unique_salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that we have 8454 different values now this is a big problem because its not very useful to us with all those outcomes. I will round the values to the nearest thousands that way we can get a general prediction to do. We could use a regression method, but that is outside the scope of this class. I will try to reduce the number of unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([64000.0, 96000.0, 21000.0, 42000.0, 7000.0, 110000.0, 63000.0, 84000.0, 78000.0, 41000.0, 162000.0, 156000.0, 62000.0, 85000.0, 19000.0, 40000.0, 92000.0, 130000.0, 61000.0, 18000.0, 35000.0, 39000.0, 182000.0, 60000.0, 74000.0, 153000.0, 17000.0, 124000.0, 38000.0, 81000.0, 200000.0, 59000.0, 16000.0, 120000.0, 37000.0, 58000.0, 31000.0, 135000.0, 15000.0, 115000.0, 36000.0, 70000.0, 86000.0, 170000.0, 57000.0, 14000.0, 77000.0, 99000.0, 138000.0, 56000.0, 20000.0, 13000.0, 80000.0, 168000.0, 34000.0, 91000.0, 190000.0, 55000.0, 12000.0, 98000.0, 132000.0, 33000.0, 54000.0, 73000.0, 129000.0, 75000.0, 32000.0, 144000.0, 114000.0, 53000.0, 10000.0, 87000.0, 125000.0, 152000.0, 95000.0, 52000.0, 94000.0, 9000.0, 30000.0, 5000.0, 175000.0, 51000.0, 8000.0, 76000.0, 88000.0, 172000.0, 29000.0, 50000.0, 83000.0, 71000.0, 82000.0, 140000.0, 28000.0, 90000.0, 49000.0, 134000.0, 97000.0, 108000.0, 192000.0, 27000.0, 163000.0, 48000.0, 72000.0, 105000.0, 69000.0, 160000.0, 26000.0, 79000.0, 47000.0, 102000.0, 68000.0, 150000.0, 128000.0, 25000.0, 46000.0, 93000.0, 67000.0, 180000.0, 24000.0, 100000.0, 45000.0, 122000.0, 66000.0, 11000.0, 23000.0, 44000.0, 6000.0, 199000.0, 65000.0, 145000.0, 22000.0, 89000.0, 43000.0])\n",
      "133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>BinnedSalaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>27000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Engineering Systems Analyst   \n",
       "1                            Stress Engineer Glasgow   \n",
       "2                   Modelling and simulation analyst   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractTime  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking    permanent   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow    permanent   \n",
       "2  Hampshire, South East, South East          Hampshire    permanent   \n",
       "3     Surrey, South East, South East             Surrey    permanent   \n",
       "4     Surrey, South East, South East             Surrey    permanent   \n",
       "\n",
       "                        Company          Category  \\\n",
       "0  Gregory Martin International  Engineering Jobs   \n",
       "1  Gregory Martin International  Engineering Jobs   \n",
       "2  Gregory Martin International  Engineering Jobs   \n",
       "3  Gregory Martin International  Engineering Jobs   \n",
       "4  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized  BinnedSalaries  \n",
       "0              20000 - 30000/annum 20-30K             25000         25000.0  \n",
       "1              25000 - 35000/annum 25-35K             30000         30000.0  \n",
       "2              20000 - 40000/annum 20-40K             30000         30000.0  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500         27000.0  \n",
       "4              20000 - 30000/annum 20-30K             25000         25000.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SalaryNormalized = list(salary_table.SalaryNormalized)\n",
    "small_salaries = [ elem/1000 for elem in SalaryNormalized ]\n",
    "rounded_salaries = [ '%.1f' % elem for elem in small_salaries ]\n",
    "big_salaries = [ float(elem)*1000 for elem in rounded_salaries ]\n",
    "set_salaries = set(big_salaries)\n",
    "print(set_salaries)\n",
    "print(len(set_salaries))\n",
    "salary_table['BinnedSalaries'] = pd.Series(big_salaries)\n",
    "salary_table.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(salary_table)):\n",
    "    row = salary_table.iloc[i]\n",
    "    if isinstance(row['Title'],float):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the instance of the missing title that we saw earlier in the notebook, luckily the full description contained the title. I just filled it in that way we could do predictions easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                       Quality Improvement Manager\n",
       "FullDescription       Quality Improvement Manager North West England...\n",
       "LocationRaw                                       Liverpool, Merseyside\n",
       "LocationNormalized                                            Liverpool\n",
       "ContractTime                                                        NaN\n",
       "Company                                                             NaN\n",
       "Category                                      Healthcare & Nursing Jobs\n",
       "SalaryRaw                                     40,000 to 45,000 per year\n",
       "SalaryNormalized                                                  42500\n",
       "BinnedSalaries                                                    42000\n",
       "Name: 1588, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_table.at[1588,'Title'] = \"Quality Improvement Manager\"\n",
    "salary_table.iloc[1588]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "133 is small enough I think, because we have a large enough data set to get good counts for each of the bins\n",
    "Now that we have made our data more consice we are ready to begin working with our dataset to create models that will hopefully give us strong predictions.\n",
    "\n",
    "## Wrangling for Models\n",
    "\n",
    "This is some hot encoding for the forest. I defined a cut in the dataset, putting it into two bins, the reason is dicussed later in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean  = salary_table[\"BinnedSalaries\"].mean()\n",
    "sd = salary_table[\"BinnedSalaries\"].var()**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_type =  pd.get_dummies(salary_table['ContractTime'], prefix = 'type', dummy_na=True)\n",
    "salary_table = salary_table.join(ohe_type)\n",
    "ohe_cat =  pd.get_dummies(salary_table['Category'], prefix = 'cat', dummy_na=False)\n",
    "salary_table = salary_table.join(ohe_cat)\n",
    "salary_table['normal'] = salary_table.apply(lambda row: 1 if ((row.BinnedSalaries < mean+sd) and (row.BinnedSalaries > mean-sd)) else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                                              Theatre Manager Wirral\n",
       "FullDescription                         UK Healthcare Professionals are currently recr...\n",
       "LocationRaw                                                        The Wirral, Merseyside\n",
       "LocationNormalized                                                                     UK\n",
       "ContractTime                                                                          NaN\n",
       "Company                                                                               NaN\n",
       "Category                                                        Healthcare & Nursing Jobs\n",
       "SalaryRaw                                                   40000.00 to 45000.00 per year\n",
       "SalaryNormalized                                                                    42500\n",
       "BinnedSalaries                                                                      42000\n",
       "type_contract                                                                           0\n",
       "type_permanent                                                                          0\n",
       "type_nan                                                                                1\n",
       "cat_Accounting & Finance Jobs                                                           0\n",
       "cat_Admin Jobs                                                                          0\n",
       "cat_Charity & Voluntary Jobs                                                            0\n",
       "cat_Consultancy Jobs                                                                    0\n",
       "cat_Creative & Design Jobs                                                              0\n",
       "cat_Customer Services Jobs                                                              0\n",
       "cat_Domestic help & Cleaning Jobs                                                       0\n",
       "cat_Energy, Oil & Gas Jobs                                                              0\n",
       "cat_Engineering Jobs                                                                    0\n",
       "cat_Graduate Jobs                                                                       0\n",
       "cat_HR & Recruitment Jobs                                                               0\n",
       "cat_Healthcare & Nursing Jobs                                                           1\n",
       "cat_Hospitality & Catering Jobs                                                         0\n",
       "cat_IT Jobs                                                                             0\n",
       "cat_Legal Jobs                                                                          0\n",
       "cat_Logistics & Warehouse Jobs                                                          0\n",
       "cat_Maintenance Jobs                                                                    0\n",
       "cat_Manufacturing Jobs                                                                  0\n",
       "cat_Other/General Jobs                                                                  0\n",
       "cat_PR, Advertising & Marketing Jobs                                                    0\n",
       "cat_Part time Jobs                                                                      0\n",
       "cat_Property Jobs                                                                       0\n",
       "cat_Retail Jobs                                                                         0\n",
       "cat_Sales Jobs                                                                          0\n",
       "cat_Scientific & QA Jobs                                                                0\n",
       "cat_Social work Jobs                                                                    0\n",
       "cat_Teaching Jobs                                                                       0\n",
       "cat_Trade & Construction Jobs                                                           0\n",
       "cat_Travel Jobs                                                                         0\n",
       "normal                                                                                  1\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_table.iloc[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the normal column should have about 68% of the data within it, this comes from an assumption that the salaries are going to be normally distributed due to the central limit theorum.\n",
    "\n",
    "Big bag for big predictions\n",
    "\n",
    "initialize a dict with binned salaires and 0 values then for each word that is associated with that value just drop the +1 in that one. The dict is gonna have 133 keys, but there is a lot of words. Should be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_wrangler here\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def sentence_wrangler(sentence, swords, legal_chars):\n",
    "    removed_words= []\n",
    "    result = []\n",
    "    word_tokes = word_punct_tokenizer.tokenize(sentence.lower())\n",
    "    for item in word_tokes:\n",
    "        x = re.findall(legal_chars, item)\n",
    "        if item in swords:\n",
    "            removed_words.append(x)\n",
    "        elif len(x) > 0:\n",
    "            result.append(x)\n",
    "        return result, removed_words\n",
    "\n",
    "reference = sorted(list(set_salaries))\n",
    "empty_reference = [0] * 133\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "caps = \"([A-Z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snapu\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "1270.12000012\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "bag_of_fulldesc = {}\n",
    "bag_of_loc = {}\n",
    "bag_of_title = {}\n",
    "\n",
    "for i in range(len(salary_table)):\n",
    "    row = salary_table.iloc[i]\n",
    "    text1 = row['FullDescription']\n",
    "    text1 = split_into_sentences(text1)\n",
    "    for sentence in text1:\n",
    "        jobdesc = sentence_wrangler(sentence, stopwords.words('english'), r'^[a-z]+$')[0]\n",
    "        for words in jobdesc:\n",
    "            for word in words:\n",
    "                if word not in bag_of_fulldesc:\n",
    "                    bag_of_fulldesc[word] = [0] * 133\n",
    "                bag_of_fulldesc[word][reference.index(row['BinnedSalaries'])] +=1\n",
    "                \n",
    "    loc = salary_table.loc[i, 'LocationNormalized'].lower()\n",
    "    loc = loc.split(\" \")\n",
    "    if len(loc)>1:\n",
    "        for words in loc:\n",
    "            if word not in bag_of_loc:\n",
    "                bag_of_loc[word] = [0] * 133\n",
    "            bag_of_loc[word][reference.index(row['BinnedSalaries'])] +=1\n",
    "    else:\n",
    "        if loc[0] not in bag_of_loc:\n",
    "            bag_of_loc[loc[0]] = [0] * 133\n",
    "        bag_of_loc[loc[0]][reference.index(row['BinnedSalaries'])] +=1\n",
    "            \n",
    "    title = salary_table.loc[i, 'Title'].lower()\n",
    "    title = title.split(\" \")\n",
    "    for word in title:\n",
    "        if word not in bag_of_title:\n",
    "            bag_of_title[word] = [0] * 133\n",
    "        bag_of_title[word][reference.index(row['BinnedSalaries'])] +=1\n",
    "                \n",
    "                         \n",
    "    if i%4000 == 0: print('4000 more')\n",
    "                \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm only took about 20 minutes to run, I would say that's pretty efficient for the ~250,000 columns in the data set. Now lets just make sure the numbers are reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('louthcaritasrecruitment', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      "[('activating', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      "[('information/data', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_fulldesc.items()[100:101])\n",
    "print(bag_of_loc.items()[100:101])\n",
    "print(bag_of_title.items()[100:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Next I'll generate up the counts that we need to use the Naive Bayes ensemble on the full description, normalized location and the title of the job. I need to count up the number of occurances of the Binned Salaries and then I can use that as probabilities in the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_counts = {'salary_count': len(salary_table)}\n",
    "class_counts = [0] * 133\n",
    "for i in range(len(salary_table)):\n",
    "    salary = salary_table.iloc[i]['BinnedSalaries']\n",
    "    class_counts[reference.index(salary_table.iloc[i]['BinnedSalaries'])] += 1\n",
    "    \n",
    "    salary_sum = float(sum(class_counts))\n",
    "    class_prob = [0] * 133\n",
    "    for i in range(len(class_counts)):\n",
    "        class_prob[i] = class_counts[i]/salary_sum\n",
    "        \n",
    "    useful_counts['class_count'] = class_counts\n",
    "    useful_counts['class_prob'] = class_prob\n",
    "    \n",
    "    useful_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Modeling \n",
    "    \n",
    "   We wrangled the data and set up what we need, now we can create some models. I will be mixing the random forest model on the catagorical columns and then use Naive Bayes on the language based columns. I will then but them together in an ensemble and have them vote for which of the salaries the a new job belongs in.\n",
    "\n",
    "   To make the processing faster, I will have the locations be used from the Naive Bayes instead of the random forests for now, but if the predictions aren't as strong as I would like I think using random forests to be split using different features and then have the location for the leaves will produce good results. The computation time is just a very large worry. \n",
    "\n",
    "### Naive Bayes \"Regression\"\n",
    "\n",
    "\n",
    "   For the Naive Bayes I will use unique words that occur in the job descriptions to speed up computation time. I think each job description is roughly 200+ words. If we didn't utilize the unique words, then we are just enforcing similar probabilties onto the data, which could result in bias estimations.\"\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t build_pred\t build_tree_iter\t caser\t closest_centroid\t compute_mean\t compute_prediction\t compute_training\t euclidean_distance\t \n",
      "f1\t find_best_splitter\t forest_builder\t generate_table\t gig\t gini\t informedness\t initialize_centroids\t k_fold\t \n",
      "k_means\t phase_1\t phase_2\t predictor_case\t probabilities\t row_to_vect\t seeder\t sentence_wrangler\t split_into_sentences\t \n",
      "tree_predictor\t vote_taker\t \n"
     ]
    }
   ],
   "source": [
    "#useful functions for random forest modeling\n",
    "import os\n",
    "import sys\n",
    "home_path =  os.path.expanduser('~')\n",
    "sys.path.append(home_path + '\\\\Documents\\\\CIS 399\\\\Winter Term\\\\datascience_1')\n",
    "from week7 import *\n",
    "%who function\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snapu\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "4000 more\n",
      "1248.99100018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "  \n",
    "all_predictions = []\n",
    "\n",
    "def naive_bayes_list(lis, bag, counts):\n",
    "    listo = []\n",
    "    for i in range(133):\n",
    "        ego = 1.0\n",
    "        for word in lis:\n",
    "            ego *= ((bag[word[0]][i]+0.0)/counts['class_count'][i])\n",
    "        p = ego*counts['class_prob'][i]+0.0\n",
    "        listo.append(p)\n",
    "    return listo\n",
    "\n",
    "def naive_bayes_loc(word, bag, counts):\n",
    "    listo = []\n",
    "    for i in range(133):\n",
    "        ego = 1.0\n",
    "        ego *= ((bag[word[0]][i]+0.0)/counts['class_count'][i])\n",
    "        p = ego*counts['class_prob'][i]+0.0\n",
    "        listo.append(p)\n",
    "    return listo\n",
    "\n",
    "for i in range(len(salary_table)):\n",
    "    sub_list = []\n",
    "\n",
    "    unique1 = []\n",
    "    text1 = salary_table.loc[i, 'FullDescription']\n",
    "    text1 = split_into_sentences(text1)\n",
    "    for sentence in text1:\n",
    "        wrangled_text = sentence_wrangler(sentence, stopwords.words('english'), r'^[a-z]+$')[0]\n",
    "        for word in wrangled_text:\n",
    "            if word not in unique1: \n",
    "                unique1.append(word)\n",
    "    result1 = naive_bayes_list(unique1, bag_of_fulldesc, useful_counts)\n",
    "    sub_list.append(result1.index(max(result1)))\n",
    "        \n",
    "    unique2 = []\n",
    "        \n",
    "    text2 = salary_table.loc[i, 'LocationNormalized'].lower()\n",
    "    text2 = text2.split(\" \")\n",
    "    if len(text2) == 1:\n",
    "        result2 = naive_bayes_loc(text2,bag_of_loc, useful_counts)\n",
    "    else:\n",
    "        for word in text2:\n",
    "            if word not in unique2: \n",
    "                unique3.append(text2)\n",
    "        result2 = naive_bayes_list(text2, bag_of_title, useful_counts)\n",
    "    sub_list.append(result2.index(max(result2)))\n",
    "            \n",
    "    unique3 = []\n",
    "        \n",
    "    text3 = salary_table.loc[i, 'Title'].lower()\n",
    "    text3 = text3.split(\" \")\n",
    "    if len(text3) == 1:\n",
    "        result3 = naive_bayes_loc(text3,bag_of_title, useful_counts)\n",
    "    else:\n",
    "        for word in text3:\n",
    "            if word not in unique3: \n",
    "                unique3.append(text3)\n",
    "        result3 = naive_bayes_list(unique3, bag_of_title, useful_counts)\n",
    "    sub_list.append(result3.index(max(result3)))\n",
    "        \n",
    "        \n",
    "        \n",
    "    all_predictions.append(tuple(sub_list))\n",
    "    if i%4000 == 0: print('4000 more')\n",
    "end = time.time()\n",
    "print(end - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again a nice 20 minutes run time. I'd say im quite please with the efficiency of this code to turn out three predictions that quickly, especially considering the size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('nb_predictions.txt', 'w') as file:\n",
    "    file.write(json.dumps(all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = json.load(open(\"nb_predictions.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 15, 109], [35, 13, 66], [35, 30, 99], [50, 30, 109], [30, 30, 20], [45, 15, 109], [40, 25, 96], [17, 30, 15], [22, 12, 15], [30, 45, 83]]\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at the values returned for the first 10, there are numerous things to consider. Since we are focusing on the use of NLP to determine the salary data, this allows us to do a few things with the random forests on the catagorical variables.\n",
    "\n",
    "First, we can use the Random Forest to have those come up with it's own predictions based on the data and then put all of the predictions together and then come up with a way to get a single prediction for the salary based on all the predictions, but how can we get a random forest to predict multiple values, this seems pretty complicated and would require quite a bit of changing to the algorithmns at hand. Perhaps this isn't the best idea.\n",
    "\n",
    "Second, we could use the random forest as a mean to refine the predictions that we have gotten. I think making the random forests check to see if the predicted values are in or out of a certain range would be a very cool way to use it. Hopefully the implementation is effective. \n",
    "\n",
    "Third, how are we going to test how well this model does in predicting the data. I think if we interpret the Naive Bayes and Random Forest matrix to be sort of a linear regression of sorts we can assess it's predictive power based on similar concepts. We can calculate something called the Root Mean Squared Prediction Error and see how well this concept works. \n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Since the data is already wrangled and we have imported our functions, I will create a random forest in which will return predicted values similar to the ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_columns = ['type_contract',\n",
    "       'type_permanent', 'type_nan', 'cat_Accounting & Finance Jobs',\n",
    "       'cat_Admin Jobs', 'cat_Charity & Voluntary Jobs',\n",
    "       'cat_Consultancy Jobs', 'cat_Creative & Design Jobs',\n",
    "       'cat_Customer Services Jobs', 'cat_Domestic help & Cleaning Jobs',\n",
    "       'cat_Energy, Oil & Gas Jobs', 'cat_Engineering Jobs',\n",
    "       'cat_Graduate Jobs', 'cat_HR & Recruitment Jobs',\n",
    "       'cat_Healthcare & Nursing Jobs', 'cat_Hospitality & Catering Jobs',\n",
    "       'cat_IT Jobs', 'cat_Legal Jobs', 'cat_Logistics & Warehouse Jobs',\n",
    "       'cat_Maintenance Jobs', 'cat_Manufacturing Jobs',\n",
    "       'cat_Other/General Jobs', 'cat_PR, Advertising & Marketing Jobs',\n",
    "       'cat_Part time Jobs', 'cat_Property Jobs', 'cat_Retail Jobs',\n",
    "       'cat_Sales Jobs', 'cat_Scientific & QA Jobs',\n",
    "       'cat_Social work Jobs', 'cat_Teaching Jobs',\n",
    "       'cat_Trade & Construction Jobs', 'cat_Travel Jobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7322893515492221, 0.8454584690419307, 0.0)\n",
      "136.38499999\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "forest1 = forest_builder(salary_table, splitter_columns, 'normal', hypers={'total-trees':5})\n",
    "salary_table['forest_1'] = salary_table.apply(lambda row: vote_taker(row, forest1), axis=1)\n",
    "salary_table['forest_1_type'] = salary_table.apply(lambda row: predictor_case(row, pred='forest_1', target='normal'), axis=1)\n",
    "forest1_types = salary_table['forest_1_type'].value_counts()\n",
    "print((accuracy(forest1_types), f1(forest1_types), informedness(forest1_types)))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7322893515492221, 0.8454584690419307, 0.0)\n",
      "0.0480000972748\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "forest2 = forest_builder(salary_table, splitter_columns, 'normal', hypers={'total-trees':11})\n",
    "salary_table['forest2'] = salary_table.apply(lambda row: vote_taker(row, forest2), axis=1)\n",
    "salary_table['forest2_type'] = salary_table.apply(lambda row: predictor_case(row, pred='forest2', target='normal'), axis=1)\n",
    "forest2_types = salary_table['forest2_type'].value_counts()\n",
    "print((accuracy(forest2_types), f1(forest2_types), informedness(forest2_types)))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm a little surprised that the random forest scores as well as it does under these conditions. We can see that the size of the forest after 5 does not improve the ability of prediction. I tried to introduce the normlaized location as a catagorical variable in the random forest and kept coming up with errors, so I will not include it into the random forest as it's already captured in the Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have models for our data now we have to assess the ensemble together and see how to get a singular value, as well as assessing how well our model performs to the test set.\n",
    "\n",
    "## All together now\n",
    "\n",
    "So I think putting more weight to the fulldescription prediction is going to yeild the best results, I would like to find some way to weigh the predictive power of each of predictions and then get a weighted average of sorts. \n",
    "\n",
    "I think allowing for the location and the title to affect the prediction on the full description is going to be best. \n",
    "\n",
    "Using the Random Forest to check if the predictions given the type of work as well as the sector of work is good will be a sort of verification of the prediction given by naive bayes. If the predictions of the Naive Bayes doesn't correspond to the random forest then the weights of the other predictions will be changed to hopefully account for the differences in the sector and the longevity of the position.\n",
    "\n",
    "First things first, lets get all the predictions together into a matrix so we can more efficiently do our calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[30, 15, 109, 1],\n",
       " [35, 13, 66, 1],\n",
       " [35, 30, 99, 1],\n",
       " [50, 30, 109, 1],\n",
       " [30, 30, 20, 1]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(salary_table)):\n",
    "    all_predictions[i].append(salary_table.iloc[i]['forest_1'])\n",
    "all_predictions[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with weighting it as 85%,10%,5% to start for the Naive Bayes Predictions, maybe I can find a better weighting that will minimize the RMSPE. After I'll check to see if it's valid, if it's not we will add or subtract a std. dev to the predictions and see how that performs. I chose to move it by a single standard deviation under some sort of intuition that if the original prediction of the random forest says it's outside of the normal standard deiviation around the mean then the model predictions should reflect this. I think this will make a tighter fit around the actual values and increase prediction power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17683.6768553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean \n",
    "print(sd)\n",
    "reference.index(35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37000.0,\n",
       " 39000.0,\n",
       " 43000.0,\n",
       " 56000.0,\n",
       " 35000.0,\n",
       " 50000.0,\n",
       " 46000.0,\n",
       " 23000.0,\n",
       " 26000.0,\n",
       " 39000.0]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction_condenser(predictions, weights):\n",
    "    cp = []\n",
    "    preds = []\n",
    "    for i in range(len(predictions)):\n",
    "        cp.append((int(predictions[i][0])*weights[0])+(int(predictions[i][1])*weights[1])+(int(predictions[i][2])*weights[2]))\n",
    "        rounded = round(cp[i],0)\n",
    "        ps = reference[int(rounded)] \n",
    "        if predictions[3] == 1:\n",
    "            if (ps > mean): \n",
    "                ps -= sd\n",
    "            else:\n",
    "                ps += sd\n",
    "        if predictions[3] == 0:\n",
    "            if ((ps < mean) and (ps > mean)):\n",
    "                if predictions[0]<30:\n",
    "                    ps -= sd\n",
    "                else:\n",
    "                    ps += sd\n",
    "        preds.append(ps)\n",
    "    return preds\n",
    "\n",
    "pred_reg = prediction_condenser(all_predictions, [.85,.1,.05])\n",
    "pred_reg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14720.601765\n",
      "17683.6768553\n"
     ]
    }
   ],
   "source": [
    "def rmse(predictions, targets):\n",
    "    diffs = 0\n",
    "    for i in range(len(predictions)):\n",
    "        diffs += (predictions[i] - targets[i])**2\n",
    "    mean_diffs = diffs/len(predictions)\n",
    "    rmspe = (mean_diffs)**.5\n",
    "    return rmspe \n",
    "\n",
    "print(rmse(pred_reg, big_salaries))\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE is better than the standard deviation of the underlying dataset, I would say we have done good here. Perhaps an $R^2$ would be a better measure of fit. I would feel confident using the $R^2$ statistic as I think our results of predictions fit the qualifications of a linear model. Perhaps not a very traditional OLS model, but none-the-less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929593544812951"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def r2(predictions, targets):\n",
    "    num = 0\n",
    "    for i in range(len(predictions)):\n",
    "        num += (predictions[i] - targets[i])**2\n",
    "    dem = 0\n",
    "    mean = sum(targets)/len(targets)\n",
    "    for i in range(len(targets)):\n",
    "        dem += (targets[i] - mean)**2\n",
    "    return (num/dem)\n",
    "r2(pred_reg, big_salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, we are capturing about 70% of the variation of Salaries from our model. Not bad, Im sure we can do better with some more tweaking to the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".90,.05,.05 -> R2:0.719595638522\n",
      ".95,.04,.01 -> R2:0.755323818323\n",
      ".95,.01,.04 -> R2:0.751398375485\n",
      ".98,.01,.01 -> R2:0.778603669749\n",
      "1.0,.00,.00 -> R2:0.794102558184\n"
     ]
    }
   ],
   "source": [
    "pred_reg = prediction_condenser(all_predictions, [.90,.05,.05])\n",
    "print(\".90,.05,.05 -> R2:\"+str(r2(pred_reg, big_salaries)))\n",
    "\n",
    "pred_reg = prediction_condenser(all_predictions, [.95,.04,.01])\n",
    "print(\".95,.04,.01 -> R2:\"+str(r2(pred_reg, big_salaries)))\n",
    "\n",
    "pred_reg = prediction_condenser(all_predictions, [.95,.01,.04])\n",
    "print(\".95,.01,.04 -> R2:\"+str(r2(pred_reg, big_salaries)))\n",
    "\n",
    "pred_reg = prediction_condenser(all_predictions, [.98,.01,.01])\n",
    "print(\".98,.01,.01 -> R2:\"+str(r2(pred_reg, big_salaries)))\n",
    "\n",
    "pred_reg = prediction_condenser(all_predictions, [1,.00,.00])\n",
    "print(\"1.0,.00,.00 -> R2:\"+str(r2(pred_reg, big_salaries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, it seems I gave too much importance to the Location and the Title. Either way with this \"Naive Bayes Regression\" of sorts, having an $R^2$ value of .794 is more one that I didn't think would be so large.\n",
    "\n",
    "I think it may be worth seeing how just the full description predictions measure up to the power and see if our methods of tweaking the predictions on the standard deviations helped or hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941025581838882"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_fulldesc=[]\n",
    "for i in range(len(all_predictions)):\n",
    "    ps = reference[all_predictions[i][0]] \n",
    "    nb_fulldesc.append(ps)\n",
    "    \n",
    "r2(nb_fulldesc, big_salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "It appears that the naive bayes on the full description of the job was the best performance I could have done. I would have thought that other factors would have counted more, or should be weighted more, such as location and sectors. It seems the Naive Bayes did a good job at catching and accounting for outliers, which I thought the random forest would help correct. The location was causing better prediction then the Title for the Naive Bayes, but the fulldescription itself did a very good job at the prediction alone. It seems the ensemble approach failed in this instance.\n",
    "\n",
    "I think the ensemble approach may not have been the best course of action due to the full description typically containing the location and the title, but I felt like those would have a larger impact on the salary then just the occurance of the words themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
